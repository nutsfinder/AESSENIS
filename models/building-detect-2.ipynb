{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1646193,"sourceType":"datasetVersion","datasetId":973429},{"sourceId":7350228,"sourceType":"datasetVersion","datasetId":4268416},{"sourceId":7924378,"sourceType":"datasetVersion","datasetId":4657145}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# INSTALL REQUIREMENTS","metadata":{}},{"cell_type":"code","source":"!pip install -r /kaggle/input/bd-requirements/bd_requirements.txt","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-10T20:29:02.804951Z","iopub.execute_input":"2024-03-10T20:29:02.805335Z","iopub.status.idle":"2024-03-10T20:30:23.060454Z","shell.execute_reply.started":"2024-03-10T20:29:02.805301Z","shell.execute_reply":"2024-03-10T20:30:23.059348Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# IMPORTING LIBRARIES","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport random\nimport math\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom skimage import io, transform\nimport rasterio as rio\nfrom rasterio import features\nfrom pathlib import Path\nimport pathlib\nimport geopandas as gpd\nfrom PIL import Image\nimport xarray as xr\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom collections import defaultdict\nimport torch\nimport torch.optim as optim\nfrom torch import nn\nfrom torch.optim import lr_scheduler\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler\n# from transformers import get_cosine_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:30:23.062737Z","iopub.execute_input":"2024-03-10T20:30:23.06303Z","iopub.status.idle":"2024-03-10T20:30:34.311355Z","shell.execute_reply.started":"2024-03-10T20:30:23.063003Z","shell.execute_reply":"2024-03-10T20:30:34.310613Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GETTING FILE PATHS","metadata":{}},{"cell_type":"code","source":"def combine_files(image_path, label_path):\n    files = {'image': image_path, 'mask': label_path}\n    return files\n\ndef get_files(base_dir):\n    subfolders = sorted(glob.glob(os.path.join(base_dir, '*')))\n    files_list = []\n\n    for subfolder in subfolders:\n        images = sorted(glob.glob(os.path.join(subfolder, \"images/*\")))\n        labels = sorted(glob.glob(os.path.join(subfolder, \"labels_match/*\")))\n        \n        # Assuming the number of images and labels is the same for each subfolder\n        for image_path, label_path in zip(images, labels):\n            files_list.append(combine_files(image_path, label_path))\n\n    return files_list","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:30:34.3127Z","iopub.execute_input":"2024-03-10T20:30:34.31299Z","iopub.status.idle":"2024-03-10T20:30:34.319865Z","shell.execute_reply.started":"2024-03-10T20:30:34.312964Z","shell.execute_reply":"2024-03-10T20:30:34.318879Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\nbase_directory = \"/kaggle/input/spacenet-7-multitemporal-urban-development/SN7_buildings_train/train\"\nfiles = get_files(base_directory)\nprint(len(files))\nfiles = random.sample(files, 500)\nprint(len(files))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-10T20:30:34.321338Z","iopub.execute_input":"2024-03-10T20:30:34.321632Z","iopub.status.idle":"2024-03-10T20:30:36.523171Z","shell.execute_reply.started":"2024-03-10T20:30:34.321602Z","shell.execute_reply":"2024-03-10T20:30:36.522207Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SETTING UP DATALOADER","metadata":{}},{"cell_type":"code","source":"class SpaceNet7(Dataset):\n    def __init__(self, files, tile_size, transforms_=None):\n        self.files = files\n        self.tile_size = tile_size\n        self.transforms_ = transforms_\n\n    def rasterize_geojson(self, idx):\n        # Read the GeoJSON file using GeoPandas\n        gdf = gpd.read_file(self.files[idx]['mask'])\n        # Open the reference raster using Rasterio\n        with rio.open(self.files[idx]['image']) as raster:\n            # Read the first band of the raster\n            r = raster.read(1)\n            # Reproject the GeoDataFrame to EPSG:3857\n            gdf = gdf.to_crs('epsg:3857')\n            # Initialize an empty mask with zeros\n            mask = np.zeros_like(r, dtype=np.uint8)\n            # Iterate over geometries and set corresponding values in the mask to 255\n            for geom in gdf['geometry']:\n                # Convert the geometry to the pixel coordinates in the reference raster\n                geom_px = features.geometry_mask([geom], transform=raster.transform, out_shape=r.shape, invert=True)\n                # Set the corresponding values in the mask to 1\n                mask[geom_px] = 1\n            return mask\n\n# gotten from https://www.kaggle.com/code/nghihuynh/wsi-preprocessing-tiling-tissue-segmentation\n    def make_tiles(self, img, mask, tile_size=128):\n        '''\n        img: np.ndarray with dtype np.uint8 and shape (width, height, channel)\n        mask: np.ndarray with dtype np.uint9 and shape (width, height)\n        '''\n        w_i, h_i, ch = img.shape\n        w_m, h_m = mask.shape\n\n        pad0, pad1 = (tile_size - w_i%tile_size) % tile_size, (tile_size - h_i%tile_size) % tile_size\n\n        padding_i = [[pad0//2, pad0-pad0//2], [pad1//2, pad1-pad1//2], [0, 0]]\n        padding_m = [[pad0//2, pad0-pad0//2], [pad1//2, pad1-pad1//2]]\n\n        img = np.pad(img, padding_i, mode='constant', constant_values=255)\n        img = img.reshape(img.shape[0]//tile_size, tile_size, img.shape[1]//tile_size, tile_size, ch)\n        img = img.transpose(0, 2, 1, 3, 4).reshape(-1, tile_size, tile_size, ch)\n\n        mask = np.pad(mask, padding_m, mode='constant', constant_values=255)\n        mask = mask.reshape(mask.shape[0]//tile_size, tile_size, mask.shape[1]//tile_size, tile_size)\n        mask = mask.transpose(0, 2, 1, 3).reshape(-1, tile_size, tile_size)\n\n        num_tiles = len(mask)\n        return img, mask\n\n    def __getitem__(self, idx):\n        # read the images and masks as numpy arrays\n        img = np.array(Image.open(self.files[idx]['image']).convert('RGB'))\n        mask = self.rasterize_geojson(idx)\n        \n        if self.transforms_:\n            aug = self.transforms_(image=img, mask=mask)\n            img, mask = aug['image'], aug['mask']\n            \n        img, mask = self.make_tiles(img, mask, self.tile_size)\n        \n        selected_index = None\n        \n        #returns a random index from the tiled images with buildings labels in it \n        for _ in range(len(img)):  # Adjust the maximum number of iterations as needed\n            ind = random.randint(0, len(img)- 1)\n            selected_mask = mask[ind]\n    \n            # Check if selected_mask has both 1s and 0s\n            if np.any(selected_mask == 1) and np.any(selected_mask == 0):\n                img, mask = img[ind], mask[ind]\n                selected_index = ind\n                break\n    \n        # If no suitable index found, select a random one\n        if selected_index is None:\n            selected_index = random.randint(0, len(img) - 1)\n            img, mask = img[selected_index], mask[selected_index]\n            \n        #######Transpose Image##########################\n        img = img.transpose(2,1,0)\n        img = torch.tensor(img, dtype=torch.float32)\n        mask = torch.tensor(mask, dtype=torch.uint8)\n        \n        # Normalize the image tiles to the range [0, 1]\n        img_tiles_normalized = (img - img.min()) / (img.max() - img.min())\n        \n        # return img, mask\n        return img_tiles_normalized, mask\n\n    def __len__(self):\n        return len(self.files)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:30:36.526857Z","iopub.execute_input":"2024-03-10T20:30:36.527673Z","iopub.status.idle":"2024-03-10T20:30:36.551804Z","shell.execute_reply.started":"2024-03-10T20:30:36.527641Z","shell.execute_reply":"2024-03-10T20:30:36.550662Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tile_size = 64\nbatch_size = 16\n\ntrain_transforms = A.Compose([\n    A.HorizontalFlip(p=0.5)\n#     A.Blur(blur_limit=3, p=0.5)\n#     A.Rotate(limit=40, p=0.9, border_mode=cv2.BORDER_CONSTANT)\n    ],is_check_shapes = False)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\ntrain_files, val_files = train_test_split(files, test_size=0.2, random_state=42, shuffle=True)\n\ntrain_dataset = SpaceNet7(files=train_files, tile_size=tile_size, transforms_=train_transforms)\nval_dataset = SpaceNet7(files=val_files, tile_size=tile_size)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n\nprint(f'len train: {len(train_files)}')\nprint(f'len val: {len(val_files)}')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:30:36.553251Z","iopub.execute_input":"2024-03-10T20:30:36.557533Z","iopub.status.idle":"2024-03-10T20:30:37.213599Z","shell.execute_reply.started":"2024-03-10T20:30:36.557489Z","shell.execute_reply":"2024-03-10T20:30:37.212517Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VISUALIZE THE DATALOADER","metadata":{}},{"cell_type":"code","source":"def visualize_loaded_tiles(img_tiles, mask_tiles):\n    num_tiles, _, _, _ = img_tiles.shape\n    rows = int(math.sqrt(num_tiles))\n    cols = int(math.sqrt(num_tiles))\n\n    plt.figure(figsize=(15, 15))\n    # Display individual tiles with masks\n    for i, tile in enumerate(img_tiles):\n        plt.subplot(rows, cols, i + 1)\n        tile = tile.permute(2,1,0)\n        plt.imshow(tile)\n        plt.imshow(mask_tiles[i], cmap='seismic', alpha=0.5)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(f'Tile {i + 1}\\nTile Size: {tile.shape}')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:30:37.215058Z","iopub.execute_input":"2024-03-10T20:30:37.215963Z","iopub.status.idle":"2024-03-10T20:30:37.325093Z","shell.execute_reply.started":"2024-03-10T20:30:37.215926Z","shell.execute_reply":"2024-03-10T20:30:37.323932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, masks = next(iter(train_loader))\nvisualize_loaded_tiles(images, masks)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:30:37.326568Z","iopub.execute_input":"2024-03-10T20:30:37.326925Z","iopub.status.idle":"2024-03-10T20:32:09.856178Z","shell.execute_reply.started":"2024-03-10T20:30:37.326885Z","shell.execute_reply":"2024-03-10T20:32:09.855232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tile_size = 64\nbatch_size = 16\n\ntrain_transforms = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Blur(blur_limit=3, p=0.5),\n    A.Rotate(limit=40, p=0.9, border_mode=cv2.BORDER_CONSTANT)\n    ],is_check_shapes = False)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\ntrain_files, val_files = train_test_split(files, test_size=0.2, random_state=42, shuffle=True)\n\ntrain_dataset = SpaceNet7(files=train_files, tile_size=tile_size, transforms_=train_transforms)\nval_dataset = SpaceNet7(files=val_files, tile_size=tile_size)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n\nprint(f'len train: {len(train_files)}')\nprint(f'len val: {len(val_files)}')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:32:09.857513Z","iopub.execute_input":"2024-03-10T20:32:09.85811Z","iopub.status.idle":"2024-03-10T20:32:09.867428Z","shell.execute_reply.started":"2024-03-10T20:32:09.858084Z","shell.execute_reply":"2024-03-10T20:32:09.866363Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL BUILDING","metadata":{}},{"cell_type":"code","source":"class_size = 1\nmodel = smp.Unet(\n    encoder_name=\"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n    classes=class_size,                      # model output channels (number of classes in your dataset)\n)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\nprint(device)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-10T20:44:32.37243Z","iopub.execute_input":"2024-03-10T20:44:32.373087Z","iopub.status.idle":"2024-03-10T20:44:34.991776Z","shell.execute_reply.started":"2024-03-10T20:44:32.373054Z","shell.execute_reply":"2024-03-10T20:44:34.990801Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/input/build-detect-effb7/best-effb7.pth'))\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n# model.to(device)\n# print(device)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer, lr_scheduler):\n    size = len(dataloader.dataset) # number of samples\n    num_batches = len(dataloader) # batches per epoch\n    model.train() # to training mode.\n    epoch_loss = 0\n    epoch_iou_score = 0\n    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train')\n    for batch_i, batch in pbar:\n#     for batch_i, batch in enumerate(dataloader):\n        x, y = batch[0].to(device), batch[1].to(device) # move data to GPU\n        optimizer.zero_grad()\n        pred = model(x)\n        loss = loss_fn(pred, y)\n\n        loss.backward() # backpropagation to compute gradients\n        optimizer.step() # update model params\n\n        epoch_loss += loss.item() # tensor -> python value\n        pred = pred.squeeze(dim=1)\n        pred = torch.sigmoid(pred)\n        y = y.round().long()\n        tp, fp, fn, tn = smp.metrics.get_stats(pred, y, mode='binary', threshold=0.3)\n        iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\").item()\n        epoch_iou_score += iou_score\n        lr_scheduler.step(iou_score)\n    # return avg loss of epoch, acc of epoch\n    return epoch_loss/num_batches, epoch_iou_score/num_batches\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset) # number of samples\n    num_batches = len(dataloader) # batches per epoch\n    model.eval() # model to test mode.\n    epoch_loss = 0\n    epoch_iou_score = 0\n    # No gradient for test data\n    with torch.no_grad():\n        pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train')\n        for batch_i, batch in pbar:\n#         for batch_i, batch in enumerate(dataloader):\n            x, y = batch[0].to(device), batch[1].to(device) # move data to GPU\n            # Compute prediction loss\n            pred = model(x)\n            loss = loss_fn(pred, y)\n            # write to logs\n            epoch_loss += loss.item()\n            pred = pred.squeeze(dim=1)\n            pred = torch.sigmoid(pred)\n            y = y.round().long()\n            tp, fp, fn, tn = smp.metrics.get_stats(pred, y, mode='binary', threshold=0.3)\n            iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\").item()\n            epoch_iou_score += iou_score\n          \n    return epoch_loss/num_batches, epoch_iou_score/num_batches","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:32:13.457915Z","iopub.status.idle":"2024-03-10T20:32:13.458417Z","shell.execute_reply.started":"2024-03-10T20:32:13.45816Z","shell.execute_reply":"2024-03-10T20:32:13.458182Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL TRAINING","metadata":{}},{"cell_type":"code","source":"EPOCHS = 12\nlogs = {\n    'train_loss': [], 'val_loss': [],\n    'train_iou_score': [], 'val_iou_score': [],\n}\n\nif os.path.exists('/kaggle/working/checkpoints') == False:\n    os.mkdir(\"/kaggle/working/checkpoints\")\n\nloss_fn = smp.losses.DiceLoss(mode=\"binary\")\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size= 200, gamma=0.1)\nstep_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=100)\n\n# Earlystopping\npatience = 5\ncounter = 0\nbest_loss = np.inf\n\nmodel.to(device)\nfor epoch in tqdm(range(EPOCHS)):\n    train_loss, train_iou_score = train(train_loader, model, loss_fn, optimizer, step_lr_scheduler)\n    val_loss, val_iou_score = test(val_loader, model, loss_fn)\n    logs['train_loss'].append(train_loss)\n    logs['val_loss'].append(val_loss)\n    logs['train_iou_score'].append(train_iou_score)\n    logs['val_iou_score'].append(val_iou_score)\n\n    print(f'EPOCH: {str(epoch+1).zfill(3)} \\\n    train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f} \\\n    train_iou_score: {train_iou_score:.3f}, val_iou_score: {val_iou_score:.3f} \\\n    lr: {optimizer.param_groups[0][\"lr\"]}')\n    # On epoch end\n    torch.save(model.state_dict(), \"/kaggle/working/checkpoints/last.pth\")\n    # check improvement\n    if val_loss < best_loss:\n        counter = 0\n        best_loss = val_loss\n        torch.save(model.state_dict(), \"/kaggle/working/checkpoints/best.pth\")\n    else:\n        counter += 1\n    if counter >= patience:\n        print(\"Earlystop!\")\n        break","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-10T20:32:13.460284Z","iopub.status.idle":"2024-03-10T20:32:13.460768Z","shell.execute_reply.started":"2024-03-10T20:32:13.460524Z","shell.execute_reply":"2024-03-10T20:32:13.460546Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL EVALUATION","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nplt.plot(logs['train_loss'],label='Train_Loss')\nplt.plot(logs['val_loss'],label='Validation_Loss')\nplt.title('Train_Loss & Validation_Loss',fontsize=20)\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(logs['train_iou_score'],label='Train_Iou_Score')\nplt.plot(logs['val_iou_score'],label='Validation_Iou_Score')\nplt.title('Train_Iou_score & Validation_Iou_score',fontsize=20)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:32:13.46216Z","iopub.status.idle":"2024-03-10T20:32:13.462622Z","shell.execute_reply.started":"2024-03-10T20:32:13.46239Z","shell.execute_reply":"2024-03-10T20:32:13.462413Z"},"trusted":true},"outputs":[],"execution_count":null}]}